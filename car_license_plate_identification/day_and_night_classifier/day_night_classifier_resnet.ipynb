{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "998a9cfb-f70b-458c-bcd5-84700d03b560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 14:23:22.715207: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-27 14:23:22.858012: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-27 14:23:22.923265: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-27 14:23:22.943142: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-27 14:23:23.050770: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-27 14:23:24.177778: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "292358d1-11bf-459e-acc5-ef0a5bd9bf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aea5c3e9-abfb-4c50-8b14-35c4af78515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "329de883-00f3-4d93-b72d-2bcc8783807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6306 images belonging to 2 classes.\n",
      "Found 6306 images belonging to 2 classes.\n",
      "                                              File Name  Label\n",
      "0                                   train/day_00010.jpg      0\n",
      "1                                   train/day_00019.jpg      0\n",
      "2                                   train/day_00026.jpg      0\n",
      "3                                   train/day_00027.jpg      0\n",
      "4                                   train/day_00029.jpg      0\n",
      "...                                                 ...    ...\n",
      "6301                              valid/night (990).jpg      1\n",
      "6302                              valid/night (991).jpg      1\n",
      "6303                              valid/night (992).jpg      1\n",
      "6304                              valid/night (993).jpg      1\n",
      "6305  valid/.ipynb_checkpoints/day_00004-checkpoint.jpg      1\n",
      "\n",
      "[6306 rows x 2 columns]\n",
      "6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amirhosein/.pyenv/versions/3.11.9/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 871ms/step - accuracy: 0.6345 - loss: 0.1291 - val_accuracy: 0.6637 - val_loss: 0.0754\n",
      "Epoch 2/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 883ms/step - accuracy: 0.6649 - loss: 0.0682 - val_accuracy: 0.6637 - val_loss: 0.0869\n",
      "Epoch 3/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 884ms/step - accuracy: 0.6633 - loss: 0.0727 - val_accuracy: 0.6640 - val_loss: 0.0638\n",
      "Epoch 4/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 899ms/step - accuracy: 0.6569 - loss: 0.0665 - val_accuracy: 0.6638 - val_loss: 0.0632\n",
      "Epoch 5/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 901ms/step - accuracy: 0.6664 - loss: 0.0656 - val_accuracy: 0.6641 - val_loss: 0.0680\n",
      "Epoch 6/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 917ms/step - accuracy: 0.6708 - loss: 0.0656 - val_accuracy: 0.6637 - val_loss: 0.0629\n",
      "Epoch 7/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 897ms/step - accuracy: 0.6699 - loss: 0.0639 - val_accuracy: 0.6637 - val_loss: 0.0629\n",
      "Epoch 8/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 889ms/step - accuracy: 0.6764 - loss: 0.0632 - val_accuracy: 0.6637 - val_loss: 0.0629\n",
      "Epoch 9/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 882ms/step - accuracy: 0.6548 - loss: 0.0646 - val_accuracy: 0.6637 - val_loss: 0.0630\n",
      "Epoch 10/10\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 883ms/step - accuracy: 0.6585 - loss: 0.0644 - val_accuracy: 0.6638 - val_loss: 0.0644\n",
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 440ms/step - accuracy: 0.6631 - loss: 0.0645\n",
      "Validation accuracy: 0.6638122200965881\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "train_dir = 'images'\n",
    "val_dir = 'images'\n",
    "\n",
    "def extract_class(filename):\n",
    "    return 1 if 'day' in filename else 0\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory=val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "file_names = train_generator.filenames\n",
    "labels = train_generator.classes\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'File Name': file_names,\n",
    "    'Label': labels\n",
    "})\n",
    "\n",
    "print(df)\n",
    "print(len(df))\n",
    "\n",
    "# Define Focal Loss\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        y_true = K.cast(y_true, tf.float32)\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        fl = - alpha_t * K.pow((1 - p_t), gamma) * K.log(p_t)\n",
    "        return K.mean(fl)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Load ResNet50 base model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile with Focal Loss\n",
    "model.compile(optimizer=Adam(), loss=focal_loss(gamma=2., alpha=0.25), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a59d3b-39f1-4bbe-be2d-680101d61e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('day_night_model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e3de6fb-597c-4e19-96e1-8a543109ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.load_weights('day_night_model.weights.h5')\n",
    "\n",
    "    return model\n",
    "\n",
    "def classify_image(model, img_path):\n",
    "    if os.path.exists(img_path):\n",
    "        print(f\"Loading image from: {img_path}\")\n",
    "\n",
    "        print(img_path)\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "\n",
    "        prediction = model.predict(img_array)\n",
    "        \n",
    "        print(f\"Prediction value: {prediction}\")\n",
    "\n",
    "        return 'Day' if prediction > 0.5 else 'Night'\n",
    "    else:\n",
    "        print(f\"File not found: {img_path}\")\n",
    "        return None\n",
    "\n",
    "def classify_images_in_directory(model, directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        if os.path.isfile(filepath):\n",
    "            true_label = extract_class(filename)\n",
    "            \n",
    "            predicted_label = classify_image(model, filepath)\n",
    "            \n",
    "            if predicted_label is not None:\n",
    "                print(f\"File: {filename}, True Label: {'Day' if true_label == 1 else 'Night'}, \"\n",
    "                      f\"Predicted: {predicted_label}\")\n",
    "        else:\n",
    "            print(f\"Skipping {filepath}, not a file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2ca2dc-d466-4296-92c5-38eaf94178d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amirhosein/.pyenv/versions/3.11.9/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image from: images/train/day_00010.jpg\n",
      "images/train/day_00010.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621ms/step\n",
      "Prediction value: [[0.9910168]]\n",
      "The image 'images/train/day_00010.jpg' is classified as: Day\n",
      "Loading image from: images/train/day_00019.jpg\n",
      "images/train/day_00019.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction value: [[0.9767325]]\n",
      "The image 'images/train/day_00019.jpg' is classified as: Day\n",
      "Loading image from: images/train/day_00026.jpg\n",
      "images/train/day_00026.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.9372569]]\n",
      "The image 'images/train/day_00026.jpg' is classified as: Day\n",
      "Loading image from: images/train/day_01146.jpg\n",
      "images/train/day_01146.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction value: [[0.99101126]]\n",
      "The image 'images/train/day_01146.jpg' is classified as: Day\n",
      "Loading image from: images/train/day_01176.jpg\n",
      "images/train/day_01176.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Prediction value: [[0.9983656]]\n",
      "The image 'images/train/day_01176.jpg' is classified as: Day\n",
      "Loading image from: images/train/day_01246.jpg\n",
      "images/train/day_01246.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.99854654]]\n",
      "The image 'images/train/day_01246.jpg' is classified as: Day\n",
      "Loading image from: images/train/day_01372.jpg\n",
      "images/train/day_01372.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.9994075]]\n",
      "The image 'images/train/day_01372.jpg' is classified as: Day\n",
      "Loading image from: images/train/night (3074).jpg\n",
      "images/train/night (3074).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.9984514]]\n",
      "The image 'images/train/night (3074).jpg' is classified as: Day\n",
      "Loading image from: images/train/night (3078).jpg\n",
      "images/train/night (3078).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction value: [[0.9855517]]\n",
      "The image 'images/train/night (3078).jpg' is classified as: Day\n",
      "Loading image from: images/train/night (3079).jpg\n",
      "images/train/night (3079).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction value: [[0.99629277]]\n",
      "The image 'images/train/night (3079).jpg' is classified as: Day\n",
      "Loading image from: images/train/night (3131).jpg\n",
      "images/train/night (3131).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction value: [[0.9911497]]\n",
      "The image 'images/train/night (3131).jpg' is classified as: Day\n",
      "Loading image from: images/train/night (3146).jpg\n",
      "images/train/night (3146).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction value: [[0.9989411]]\n",
      "The image 'images/train/night (3146).jpg' is classified as: Day\n",
      "Loading image from: images/train/night (3241).jpg\n",
      "images/train/night (3241).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction value: [[0.98263735]]\n",
      "The image 'images/train/night (3241).jpg' is classified as: Day\n",
      "Loading image from: images/train/night (3707).jpg\n",
      "images/train/night (3707).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.99384475]]\n",
      "The image 'images/train/night (3707).jpg' is classified as: Day\n",
      "Loading image from: images/valid/day_00018.jpg\n",
      "images/valid/day_00018.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction value: [[0.98999536]]\n",
      "The image 'images/valid/day_00018.jpg' is classified as: Day\n",
      "Loading image from: images/valid/day_01179.jpg\n",
      "images/valid/day_01179.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction value: [[0.9288257]]\n",
      "The image 'images/valid/day_01179.jpg' is classified as: Day\n",
      "Loading image from: images/valid/day_01274.jpg\n",
      "images/valid/day_01274.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction value: [[0.97609925]]\n",
      "The image 'images/valid/day_01274.jpg' is classified as: Day\n",
      "Loading image from: images/valid/day_01421.jpg\n",
      "images/valid/day_01421.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.8590137]]\n",
      "The image 'images/valid/day_01421.jpg' is classified as: Day\n",
      "Loading image from: images/valid/day_01614.jpg\n",
      "images/valid/day_01614.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction value: [[0.964157]]\n",
      "The image 'images/valid/day_01614.jpg' is classified as: Day\n",
      "Loading image from: images/valid/day_02040.jpg\n",
      "images/valid/day_02040.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Prediction value: [[0.9861535]]\n",
      "The image 'images/valid/day_02040.jpg' is classified as: Day\n",
      "Loading image from: images/valid/day_00281.jpg\n",
      "images/valid/day_00281.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.9878682]]\n",
      "The image 'images/valid/day_00281.jpg' is classified as: Day\n",
      "Loading image from: images/valid/night (1419).jpg\n",
      "images/valid/night (1419).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.8745465]]\n",
      "The image 'images/valid/night (1419).jpg' is classified as: Day\n",
      "Loading image from: images/valid/night (2302).jpg\n",
      "images/valid/night (2302).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Prediction value: [[0.99038905]]\n",
      "The image 'images/valid/night (2302).jpg' is classified as: Day\n",
      "Loading image from: images/valid/night (2277).jpg\n",
      "images/valid/night (2277).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Prediction value: [[0.99388504]]\n",
      "The image 'images/valid/night (2277).jpg' is classified as: Day\n",
      "Loading image from: images/valid/night (2040).jpg\n",
      "images/valid/night (2040).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Prediction value: [[0.96851206]]\n",
      "The image 'images/valid/night (2040).jpg' is classified as: Day\n",
      "Loading image from: images/valid/night (1756).jpg\n",
      "images/valid/night (1756).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Prediction value: [[0.9820885]]\n",
      "The image 'images/valid/night (1756).jpg' is classified as: Day\n",
      "Loading image from: images/valid/night (1435).jpg\n",
      "images/valid/night (1435).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Prediction value: [[0.99499744]]\n",
      "The image 'images/valid/night (1435).jpg' is classified as: Day\n",
      "Loading image from: images/valid/night (1432).jpg\n",
      "images/valid/night (1432).jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Prediction value: [[0.9842266]]\n",
      "The image 'images/valid/night (1432).jpg' is classified as: Day\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = load_trained_model()\n",
    "\n",
    "    test_images = [\n",
    "        'images/train/day_00010.jpg',\n",
    "        'images/train/day_00019.jpg',\n",
    "        'images/train/day_00026.jpg',\n",
    "        'images/train/day_01146.jpg',\n",
    "        'images/train/day_01176.jpg',\n",
    "        'images/train/day_01246.jpg',\n",
    "        'images/train/day_01372.jpg',\n",
    "        'images/train/night (3074).jpg',\n",
    "        'images/train/night (3078).jpg',\n",
    "        'images/train/night (3079).jpg',\n",
    "        'images/train/night (3131).jpg',\n",
    "        'images/train/night (3146).jpg',\n",
    "        'images/train/night (3241).jpg',\n",
    "        'images/train/night (3707).jpg',\n",
    "    ]\n",
    "    \n",
    "    validation_images = [\n",
    "        'images/valid/day_00018.jpg',\n",
    "        'images/valid/day_01179.jpg',\n",
    "        'images/valid/day_01274.jpg',\n",
    "        'images/valid/day_01421.jpg',\n",
    "        'images/valid/day_01614.jpg',\n",
    "        'images/valid/day_02040.jpg',\n",
    "        'images/valid/day_00281.jpg',\n",
    "        'images/valid/night (1419).jpg',\n",
    "        'images/valid/night (2302).jpg',\n",
    "        'images/valid/night (2277).jpg',\n",
    "        'images/valid/night (2040).jpg',\n",
    "        'images/valid/night (1756).jpg',\n",
    "        'images/valid/night (1435).jpg',\n",
    "        'images/valid/night (1432).jpg',\n",
    "    ]\n",
    "\n",
    "    for img_path in test_images:\n",
    "        result = classify_image(model, img_path)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"The image '{img_path}' is classified as: {result}\")\n",
    "    \n",
    "    for img_path in validation_images:\n",
    "        result = classify_image(model, img_path)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"The image '{img_path}' is classified as: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
